# AnÃ¡lisis Multivariable en la ValoraciÃ³n de Viviendas en Mercados DinÃ¡micos

## ğŸ“‹ Problema que resuelve

Este proyecto aborda la predicciÃ³n de precios inmobiliarios en California, un desafÃ­o crÃ­tico para compradores, vendedores e inversores en mercados altamente dinÃ¡micos. La precisiÃ³n en la estimaciÃ³n de valores permite:

- **Para compradores**: Identificar propiedades infravaloradas
- **Para vendedores**: Establecer precios competitivos y realistas
- **Para inversores**: Evaluar retornos potenciales y tendencias de mercado

El modelo transforma variables geoespaciales y socioeconÃ³micas en predicciones precisas, superando las limitaciones de mÃ©todos tradicionales que no capturan adecuadamente las complejas relaciones entre ubicaciÃ³n, caracterÃ­sticas de la propiedad y precio.

## ğŸ”§ TecnologÃ­as utilizadas

- **Lenguajes**: Python 3.8+
- **AnÃ¡lisis de datos**: Pandas, NumPy, Matplotlib, Seaborn
- **Machine Learning**: Scikit-learn (Random Forest, Linear Regression)
- **Modelado**: Cross-validation, Grid Search, mÃ©tricas de regresiÃ³n
- **Entorno**: Jupyter Notebooks

## ğŸ—ï¸ Arquitectura y metodologÃ­a

El proyecto sigue un pipeline estructurado de ML:

1. **ExploraciÃ³n de datos**:
   - AnÃ¡lisis de distribuciones y outliers
   - Matriz de correlaciÃ³n de variables
   - VisualizaciÃ³n geoespacial de precios

2. **Preprocesamiento**:
   - TransformaciÃ³n logarÃ­tmica de distribuciones sesgadas
   - One-hot encoding de variables categÃ³ricas
   - Escalado de variables numÃ©ricas

3. **Feature Engineering**:
   - CreaciÃ³n de ratios personalizados (dormitorios/habitaciÃ³n, habitaciones/hogar)
   - IntegraciÃ³n de variables geoespaciales
   - AnÃ¡lisis de proximidad al ocÃ©ano

4. **Modelado**:
   - Entrenamiento de regresiÃ³n lineal (baseline)
   - ImplementaciÃ³n de Random Forest Regressor
   - OptimizaciÃ³n de hiperparÃ¡metros mediante Grid Search con validaciÃ³n cruzada

5. **EvaluaciÃ³n**:
   - Comparativa de modelos
   - AnÃ¡lisis de mÃ©tricas (MSE, RMSE, RÂ²)
   - InterpretaciÃ³n de importancia de variables

## ğŸ“Š Resultados y mÃ©tricas

- **PrecisiÃ³n del modelo**: RÂ² = 0.81 en datos de test
- **Mejora sobre baseline**: +14% vs. regresiÃ³n lineal (RÂ² = 0.67)
- **Feature engineering**: Incremento del 15% en capacidad predictiva mediante variables derivadas
- **Variables mÃ¡s relevantes**: Proximidad al ocÃ©ano (+0.62), ingresos medianos (+0.47), latitud (-0.36)
- **Error medio**: 8% sobre el valor real de las propiedades

## ğŸš€ PrÃ³ximos pasos

- Integrar datos temporales para capturar tendencias de mercado
- Implementar modelos de ensemble mÃ¡s complejos (XGBoost, LightGBM)
- Desarrollar API para consultas en tiempo real
- AÃ±adir visualizaciones interactivas mediante Plotly
- Experimentar con tÃ©cnicas avanzadas de feature selection

## ğŸ“ Licencia

MIT

---

*Este proyecto forma parte de mi portfolio de Data Science y estÃ¡ abierto a contribuciones y sugerencias.*
